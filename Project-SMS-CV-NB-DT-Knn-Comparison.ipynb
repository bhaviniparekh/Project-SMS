{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code is to evaluate the accuracy score of text-based SMS data over multiple classifier algorithms such as Na√Øve Bayes, \n",
    "Decision Tree, and K-nearest Neighbors. Text data requires special preparation before we can start using it for predictive \n",
    "modeling. The words need to convert to integer format. This code implements a concept called Bag of Words. In this\n",
    "approach data frame rows containing text/document are converted into a list of distinct words that are transformed into a\n",
    "feature in a new data frame. The frequency/count of these distinct words for a  row of text/document in the original data frame \n",
    "will become values in the newly transformed data frame. A new data frame is ready with distinct words as column and frequency\n",
    "of those words as a row for further steps. This whole process of converting text data to distinct words and get a count of \n",
    "these words in a given sentence/document will be implemented by the scikit library. The scikit-learn CounterVectorizer library \n",
    "provides an easy method to transform the text data.\n",
    "\n",
    "The data is read using pandas read_csv and converted to a data frame. The data is then split into X(input) and Y(output/class)\n",
    "data. We will be implementing k-fold cross-validation with fold =5 to split the X and Y data into training and testing data.\n",
    "\n",
    "The SMS data is passed over Naive Bayes, K-nearest Neighbors and Decision Tree classifiers to get the best classifier\n",
    "with the highest accuracy score. For each of the classifiers,their respective objects are created with default parameters where\n",
    "applicable. For k-nearest, training data is passed through a range of knn value to get the best knn.\n",
    "\n",
    "This project is implementing k-fold cross-validation where n_split=5. The X data is passed over a kfold object to create training\n",
    "and test data with their respective Y data. At each fold, training data is passed over CounterVectorizer object to fit and \n",
    "transform training data into frequency/count of distinct words for a row of a given sentence. Similarly, test data is transformed\n",
    "to a frequency/count of distinct words for a row of a given sentence/documents(training data's distinct words are used to transform\n",
    "test data). The transformed training data is passed over the fit method of the respective classifier object to build a model. The transformed\n",
    "test data is run through this model to predict a class for every row. The incremental prediction of test data for every fold\n",
    "is stored in a list.\n",
    "\n",
    "Finally, the accuracy score is calculated with predicted data and actual Y data.\n",
    "\n",
    "Paragraphs 4 and 5 are repeated for each of the classifiers.At the end the classifier which has the maximum accuracy score\n",
    "will be the chosen classifier for the SMS data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_data():\n",
    "    \n",
    "    '''\n",
    "    The function is to read data using pandas read_csv and convert into data frame.\n",
    "    \n",
    "    Return :-\n",
    "    data :- Adult data set data frame.\n",
    "    '''\n",
    "    \n",
    "    data=pd.read_table('https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv',header=None,names=['label','msg'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def split_data_X_Y(df):\n",
    "    \n",
    "    ''' \n",
    "    This function split the data into X(input) and Y(output/class).\n",
    "    \n",
    "    Argument : - \n",
    "    df :- Data Frame is sms data.\n",
    "    \n",
    "    Return :- \n",
    "    X :- X data\n",
    "    Y :- Y data\n",
    "  \n",
    "    '''\n",
    "     \n",
    "    Y = df.iloc[:, :-1]\n",
    "    X = df.iloc[:, -1]\n",
    "    \n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "\n",
    "def create_object_of_algo():\n",
    "    \n",
    "    '''\n",
    "    The function is to create a classifier algorithm objects.\n",
    "    Return :-\n",
    "        \n",
    "    multi_nom :-Multinominal Object.\n",
    "    dt        :- Decision Tree classifier Object.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    multi_nom = MultinomialNB()\n",
    "    \n",
    "    dt=DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    \n",
    "    return multi_nom,dt\n",
    "\n",
    "\n",
    "def kfold_split(split_val):\n",
    "    \n",
    "    '''\n",
    "    The function is to create a object of kfold with n_split value.\n",
    "    \n",
    "    Argument :- \n",
    "    split_val :- n_split value.\n",
    "    \n",
    "    Return :- \n",
    "    kfold  :- Object of Kfold.\n",
    "    \n",
    "    '''\n",
    "    kfold=KFold(n_splits=split_val)\n",
    "    \n",
    "    return kfold\n",
    "  \n",
    "\n",
    "def fit_transform_countvector(traindata_fit,testdata_fit):\n",
    "    \n",
    "    '''\n",
    "    Create an object of CounterVectorizer.Fit the training data on this object. The fit will learn the vocabulary and get a\n",
    "    a distinct list of words. After the fit, the data is transformed into an array of the count of the distinct words for every\n",
    "    row of sentences/documents. Validation data is transformed over training data sets' distinct words.\n",
    "    \n",
    "    Argument :- \n",
    "    traindata_fit :-Training \n",
    "    testdata_fit :- Validation data\n",
    "    \n",
    "    Return :- \n",
    "    x_train_transform :- Transformed training data\n",
    "    x_test_transform :- Transformed  validation data.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(traindata_fit)\n",
    "    x_train_transform=vectorizer.transform(traindata_fit)\n",
    "    x_test_transform = vectorizer.transform(testdata_fit)\n",
    "   \n",
    "    \n",
    "    return x_train_transform,x_test_transform\n",
    "\n",
    "\n",
    "\n",
    "def fit_data(xtrain_transform,y_train,obj):\n",
    "    \n",
    "    '''\n",
    "    This function is to fit the training data over the classifier algorithm library object to build a predictive model.\n",
    "    \n",
    "    Argument :- \n",
    "    xtrain_transform :- Trained transformed data.\n",
    "    y_train - ,Y-train data.\n",
    "    obj :- Classifier algorithm library object.\n",
    "    \n",
    "    Return :-\n",
    "    obj :- Classifier algorithm library object.    \n",
    "    '''\n",
    "    \n",
    "    obj.fit(xtrain_transform,y_train)\n",
    "    \n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def knn_algorithm(xdata,ydata,cv_obj):\n",
    "    \n",
    "    '''\n",
    "    This function is to fit the training data over the K-nearest Neighbor library object with the number of neighbors being\n",
    "    n_neighbors=val to build a predictive model.\n",
    "    The algorithm uses Euclidean distance as a metric for calculating the distance between the data points.\n",
    "    \n",
    "    Argument :-\n",
    "    Xdata : Transformed trained data\n",
    "    Ydata :- label/class data\n",
    "    cv_obj -: Object of kfold with n_split =3\n",
    "    \n",
    "    Return :- \n",
    "    max_v[0]:-Accuracy score\n",
    "    max_v[1] :- Knn values with highest accuracy score\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    accur_score={}\n",
    "    knn_list=list(range(3,10,2))\n",
    "    \n",
    "    for val in knn_list:\n",
    "        knn=KNeighborsClassifier(n_neighbors=val)\n",
    "        knn_score=cross_val(xdata,ydata,cv_obj,knn)\n",
    "        accur_score.update({val:knn_score})\n",
    "    \n",
    "    max_v = max(zip(accur_score.values(), accur_score.keys()))\n",
    "    \n",
    "    print(accur_score)\n",
    "    print('Accuracy   :  ' ,max_v[0],'       ' ,'Top Knn with max accuracy      :   ',max_v[1])\n",
    "    \n",
    "    return max_v[0],max_v[1]\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "def NB_algorithm(xdata,ydata,cv_obj,clf):\n",
    "    \n",
    "    '''\n",
    "    This function is to fit the training data over the Naive Bayes library object.\n",
    "    The algorithm uses the conditional probability calculation. Class with the highest probability is chosen as the prediction \n",
    "    for the validation data.\n",
    "    \n",
    "    Argument :- \n",
    "    Xdata : Transformed trained data\n",
    "    Ydata :- label/class data\n",
    "    cv_obj -: Object of kfold with n_split =3\n",
    "    clf :- Multinominal Library object\n",
    "    \n",
    "    Return :-   \n",
    "    nbscore :- Accuracy score\n",
    "        \n",
    "    '''\n",
    "        \n",
    "    nbscore=cross_val(xdata,ydata,cv_obj,clf)\n",
    "    \n",
    "    return nbscore\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def dt_algorithm(xdata,ydata,cv_obj,dt_obj):\n",
    "    \n",
    "    '''\n",
    "    This function is to fit the training data over the Decision Tree library object.\n",
    "    \n",
    "    Argument :- \n",
    "    Xdata : Transformed trained data\n",
    "    Ydata :- label/class data\n",
    "    cv_obj -: Object of kfold with n_split =3\n",
    "    dt_obj :-Decision tree lirabry object\n",
    "    \n",
    "    Return :-  \n",
    "    \n",
    "    dtscore :- accuracy score\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    dtscore=cross_val(xdata,ydata,cv_obj,dt_obj)\n",
    "    \n",
    "    return dtscore\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def pred_test(obj,xtest_transform):\n",
    "    \n",
    "    '''\n",
    "    This function is to predict validation data over the classifier training model.\n",
    "    \n",
    "    Agrument :-\n",
    "    obj :- Library Object of classifier algorithm.\n",
    "    xtest_transform :- Transfored validation data.\n",
    "    \n",
    "    Return :- \n",
    "    ypred_class :- array of predicted test data.\n",
    "    \n",
    "    '''\n",
    "   \n",
    "    \n",
    "    ypred_class = obj.predict(xtest_transform)\n",
    "    \n",
    "    return ypred_class\n",
    "\n",
    "\n",
    "\n",
    "def cross_val(xdata,ydata,kf,algo_obj):\n",
    "    \n",
    "    '''\n",
    "    K-fold cross-validation is used to split the input and output data. For every fold, training and validation text data is \n",
    "    fit and transformed over CounterVectorizer object to convert into integer format. \n",
    "    Transformed training data is fit on a given classifier algorithm object to build a predictive model.\n",
    "    Transformed validation data is predicted over this model. Incremental predicted data is stored in a series object. \n",
    "    The accuracy score is calculated at the end of the cumulative predicted data and actual class data.\n",
    "\n",
    "    Argument :- \n",
    "    Xdata : Transformed trained data\n",
    "    Ydata :- label/class data\n",
    "    kf -: Object of kfold with n_split =3\n",
    "    algo_obj :-Classifier library object\n",
    "    \n",
    "    \n",
    "    Return :-  \n",
    "    scores :- accuracy score.\n",
    "          \n",
    "    '''\n",
    "    \n",
    "    \n",
    "   \n",
    "    y_pred_final=pd.Series([])\n",
    "    for train_index,test_index in kf.split(xdata):\n",
    "        \n",
    "        \n",
    "        x_train,x_test=xdata.iloc[train_index],xdata.iloc[test_index]\n",
    "        y_train,y_test=ydata.iloc[train_index],ydata.iloc[test_index]\n",
    "          \n",
    "        # Fit and transform the training and validation data using CountVectorizer libraries. \n",
    "        xtrain_transform,xtest_transform=fit_transform_countvector(x_train,x_test)\n",
    "        \n",
    "        \n",
    "        #Fit the data of respective library object. \n",
    "        fit_data(xtrain_transform,y_train,algo_obj)\n",
    "        \n",
    "        \n",
    "        # Predict the test data.\n",
    "        \n",
    "        #Since we are going for cross validation,we need to append the predication of all folds.\n",
    "        \n",
    "        y_pred_class=pred_test(algo_obj,xtest_transform)\n",
    "        \n",
    "        for i in range(len(test_index)):\n",
    "            y_pred_final[test_index[i]]=y_pred_class[i]\n",
    "           \n",
    "               \n",
    "    scores=pred_accuracy(y_pred_final,ydata)\n",
    "        \n",
    "       \n",
    "    return scores\n",
    "        \n",
    "\n",
    "\n",
    "def pred_accuracy(y_pred_final,ydata):\n",
    "    \n",
    "    '''\n",
    "    The function is to calculate the accuracy score of predicted data and actual y data of test data set.\n",
    "    \n",
    "    Argument :- \n",
    "    y_pred_final :- Predicted data\n",
    "    ydata        :- Actual Y class data\n",
    "    \n",
    "    Return :- \n",
    "    algo_score :- Accuracy score\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    algo_score=metrics.accuracy_score(ydata,y_pred_final)\n",
    "    \n",
    "    return algo_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to hold the highest accuracy score for each of the classifier algorithm.\n",
    "best_accur_score={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To populated SMS data in a data frame.\n",
    "df_sms=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split SMS data into input(X) and output(Y) data.\n",
    "xdata,ydata=split_data_X_Y(df_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an object of k-fold cross-validation with n_split=3.\n",
    "cv_obj=kfold_split(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create objects of multiple classification algorithm ie Multinominal and Decision Tree.\n",
    "multi_nom_obj,dt_obj=create_object_of_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the Decision Tree algorithm to get the accuracy score. Populate the dictionary with the score.\n",
    "dt_score=dt_algorithm(xdata,ydata,cv_obj,dt_obj)\n",
    "best_accur_score.update({'Decision Tree':dt_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the K-nearest Neighbors algorithm to get the accuracy score. Populate the dictionary with the score.\n",
    "k_score,knear=knn_algorithm(xdata,ydata,cv_obj)\n",
    "best_accur_score.update({'Knearest - '+ str(knear):k_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the Naive Bayes to get the accuracy score. Populate the dictionary with the score.\n",
    "nb_score=NB_algorithm(xdata,ydata,cv_obj,multi_nom_obj)\n",
    "best_accur_score.update({'Naive Bayes':nb_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best algorithm for SMS data is  Naive Bayes with accuracy score of  0.9867193108399138\n"
     ]
    }
   ],
   "source": [
    "#Get the best alogorithm with higest accuracy score for the SMS data.\n",
    "best_v=max(zip(best_accur_score.values(), best_accur_score.keys()))\n",
    "print('Best algorithm for SMS data is '  , best_v[1] ,'with accuracy score of ' ,best_v[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
